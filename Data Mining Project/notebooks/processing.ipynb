{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "account_df = read_to_df(\"account.csv\")\n",
    "card_test_df = read_to_df(\"card_test.csv\")\n",
    "card_train_df = read_to_df(\"card_train.csv\")\n",
    "client_df = read_to_df(\"client.csv\")\n",
    "disp_df = read_to_df(\"disp.csv\")\n",
    "district_df = read_to_df(\"district.csv\")\n",
    "loan_test_df = read_to_df(\"loan_test.csv\")\n",
    "loan_train_df = read_to_df(\"loan_train.csv\")\n",
    "trans_test_df = read_to_df(\"trans_test.csv\")\n",
    "trans_train_df = read_to_df(\"trans_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process account data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_transactions_per_week = 3\n",
    "avg_weeks_per_month = (365.25 / 7 / 12)\n",
    "\n",
    "account_df['frequency'] = account_df['frequency'].apply(lambda x: 1 if x == 'monthly issuance' else avg_weeks_per_month if x == 'weekly issuance' else (365.25 / 7 / 12) * avg_transactions_per_week)\n",
    "account_df[\"date\"] = account_df[\"date\"].apply(lambda x: read_date(x))\n",
    "account_df.rename(columns={\"date\": \"creation_date\", \"frequency\": \"issuance_frequency_per_month\"}, inplace=True)\n",
    "\n",
    "account_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process client data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df[\"sex\"] = client_df[\"birth_number\"].apply(lambda x: 0 if int(str(x)[2:4]) > 50 else 1)\n",
    "client_df[\"age\"] = client_df[\"birth_number\"].apply(lambda x: calculate_age(read_date(x)))\n",
    "\n",
    "client_df.drop(\"birth_number\", inplace=True, axis=1)\n",
    "\n",
    "client_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process disposition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_df.rename(columns={\"type\": \"is_owner\"}, inplace=True)\n",
    "disp_df[\"is_owner\"].replace({\"OWNER\": True, \"DISPONENT\": False}, inplace=True)\n",
    "\n",
    "# Count number clients per account\n",
    "client_count_df = disp_df.groupby(\"account_id\", as_index=False, group_keys=False).agg(client_count=(\"is_owner\", \"count\"))\n",
    "\n",
    "disp_df = disp_df.merge(client_count_df, on=\"account_id\")\n",
    "disp_df = disp_df[disp_df[\"is_owner\"] == True] \n",
    "disp_df.drop(\"is_owner\", axis=1, inplace=True)\n",
    "\n",
    "disp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [trans_train_df, trans_test_df]\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    dataframes[i][\"operation\"].replace(\n",
    "        {\n",
    "            \"credit in cash\": 1,\n",
    "            \"collection from another bank\": 2,\n",
    "            \"withdrawal in cash\": 3,\n",
    "            \"remittance to another bank\": 4,\n",
    "            \"credit card withdrawal\": 5,\n",
    "            \"interest credited\": 6\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Convert \"withdrawal in cash\" to \"withdrawal\" in type column\n",
    "    dataframes[i].loc[dataframes[i][\"type\"] == \"withdrawal in cash\", \"type\"] = \"withdrawal\"\n",
    "\n",
    "    # Withdrawal amounts should be negative\n",
    "    dataframes[i].loc[dataframes[i][\"type\"] == \"withdrawal\", \"amount\"] *= -1\n",
    "\n",
    "    dataframes[i][\"date\"] = dataframes[i][\"date\"].apply(lambda x: read_date(x))\n",
    "    dataframes[i].rename(columns={\"date\": \"transaction_date\"}, inplace=True)\n",
    "\n",
    "    dataframes[i].drop([\"k_symbol\", \"bank\", \"account\"], axis=1, inplace=True)\n",
    "\n",
    "trans_train_df, trans_test_df = dataframes\n",
    "\n",
    "trans_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [card_train_df, card_test_df]\n",
    "\n",
    "for i in range(len(dataframes)):\n",
    "    dataframes[i][\"type\"].replace({\"classic\": 1, \"junior\": 2, \"gold\": 3}, inplace=True)\n",
    "    dataframes[i][\"issued\"] = dataframes[i][\"issued\"].apply(lambda x: read_date(x))\n",
    "\n",
    "card_train_df, card_test_df = dataframes\n",
    "\n",
    "card_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "district_df.replace(\"?\", np.NaN, inplace=True)\n",
    "\n",
    "district_df[\"unemploymant rate '95\"].fillna(district_df[\"unemploymant rate '95\"].median(), inplace=True)\n",
    "district_df[\"no. of commited crimes '95\"].fillna(district_df[\"no. of commited crimes '95\"].median(), inplace=True)\n",
    "\n",
    "district_df[\"unemploymant rate '95\"] = pd.to_numeric(district_df[\"unemploymant rate '95\"])\n",
    "district_df[\"no. of commited crimes '95\"] = pd.to_numeric(district_df[\"no. of commited crimes '95\"])\n",
    "\n",
    "district_df[\"criminality_growth\"] = (district_df[\"no. of commited crimes '96\"] - district_df[\"no. of commited crimes '95\"]) / district_df[\"no. of inhabitants\"]\n",
    "district_df[\"unemployment_growth\"] = (district_df[\"unemploymant rate '96\"] - district_df[\"unemploymant rate '95\"])\n",
    "district_df[\"ratio_entrepeneurs\"] = district_df[\"no. of enterpreneurs per 1000 inhabitants\"] / 1000\n",
    "\n",
    "district_df.drop([\n",
    "    \"unemploymant rate '95\",\n",
    "    \"unemploymant rate '96\",\n",
    "    \"no. of commited crimes '95\",\n",
    "    \"no. of commited crimes '96\",\n",
    "    \"no. of enterpreneurs per 1000 inhabitants\"\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process loan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dfs = [loan_train_df, loan_test_df]\n",
    "\n",
    "for i in range(len(loan_dfs)):\n",
    "    loan_dfs[i][\"date\"] = loan_dfs[i][\"date\"].apply(lambda x: read_date(x))\n",
    "    loan_dfs[i].rename(columns={\"date\": \"loan_date\", \"amount\": \"loan_amount\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate feature from transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions = (trans_train_df, trans_test_df)\n",
    "# account_features = [1, 2]\n",
    "\n",
    "# for i in range(len(transactions)):\n",
    "#     # Sorting transactions by date to figure out the most recent balance\n",
    "#     account_features[i] = transactions[i].sort_values(by=\"date\", axis=0, ascending=False)\n",
    "#     account_features[i].drop_duplicates(subset='account_id', keep='first', inplace=True)\n",
    "\n",
    "#     account_features[i].drop(account_features[i].columns.difference(['account_id', 'balance']), axis=1, inplace=True)\n",
    "#     account_features[i].rename(columns={'balance': 'final_amount'}, inplace=True)\n",
    "\n",
    "# account_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dfs = [loan_train_df, loan_test_df]\n",
    "trans_dfs = (trans_train_df, trans_test_df)\n",
    "cards_dfs = (card_train_df, card_test_df)\n",
    "\n",
    "for i in range(len(loan_dfs)):\n",
    "    # Merge with dispositions\n",
    "    loan_dfs[i] = loan_dfs[i].merge(disp_df, on=\"account_id\", how=\"left\")\n",
    "\n",
    "    # Merge with accounts\n",
    "    loan_dfs[i] = loan_dfs[i].merge(account_df, on=\"account_id\")\n",
    "\n",
    "    # Merge with clients\n",
    "    loan_dfs[i] = loan_dfs[i].merge(client_df, on=\"client_id\", suffixes=[\"_account\", \"_client\"])\n",
    "\n",
    "    # Merge with districts\n",
    "    loan_dfs[i] = loan_dfs[i].merge(district_df, left_on=\"district_id_client\", right_on=\"code\")\n",
    "\n",
    "    # Merge with cards\n",
    "    loan_dfs[i] = loan_dfs[i].merge(cards_dfs[i], on=\"disp_id\", how=\"left\")\n",
    "\n",
    "    # Merge with transactions\n",
    "    loan_dfs[i] = loan_dfs[i].merge(trans_dfs[i], on=\"account_id\", suffixes=[\"_card\", \"_transaction\"])\n",
    "\n",
    "loan_train_df, loan_test_df = loan_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode district name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train_df[\"status\"] = loan_train_df[\"status\"].apply(lambda x: True if (x == 1) else False)\n",
    "columns = [\"region\"]\n",
    "woe_encoder = ce.WOEEncoder(cols=columns)\n",
    "woe_encoded_train = woe_encoder.fit_transform(loan_train_df[columns], loan_train_df[\"status\"]).add_suffix('_woe')\n",
    "loan_train_df = loan_train_df.join(woe_encoded_train)\n",
    "loan_train_df[\"status\"] = loan_train_df[\"status\"].apply(lambda x: 1 if (x == True) else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All cards can be dropped as there are only 11 out of the total 328 loans making it very hard or impossible to fill in missing values.\n",
    "- IDs are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dfs = [loan_train_df, loan_test_df]\n",
    "\n",
    "for i in range(len(loan_dfs)):\n",
    "    loan_dfs[i].drop([\"card_id\", \"type_card\", \"issued\"], axis=1, inplace=True)\n",
    "    loan_dfs[i].drop([\"disp_id\", \"account_id\", \"client_id\"], axis=1, inplace=True)\n",
    "    loan_dfs[i].drop([\"district_id_account\", \"district_id_client\"], axis=1, inplace=True)\n",
    "    loan_dfs[i].drop([\"trans_id\"], axis=1, inplace=True)\n",
    "\n",
    "loan_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dfs = [loan_train_df, loan_test_df]\n",
    "\n",
    "def count_withdrawal(x):\n",
    "    return sum(x==\"withdrawal\")\n",
    "\n",
    "def count_credit(x):\n",
    "    return sum(x==\"credit\")\n",
    "\n",
    "for i in range(len(loan_dfs)):\n",
    "    aggregated_columns = (\"transaction_date\", \"operation\", \"amount\", \"balance\", \"type_transaction\", \"client_count\")\n",
    "    columns = [x for x in loan_dfs[i].columns.to_list() if x not in aggregated_columns]\n",
    "\n",
    "    df = loan_dfs[i].groupby(columns, as_index=False, group_keys=False, dropna=False)\n",
    "\n",
    "    num_times_under_zero = df.apply(lambda x: pd.Series(dict(\n",
    "        num_times_under_zero = (x.balance < x.payments).sum() > 2\n",
    "    )))[\"num_times_under_zero\"]\n",
    "\n",
    "    df = df.agg({\n",
    "        \"balance\": [\"mean\", \"min\", \"max\"],\n",
    "        \"transaction_date\": [\"max\"],\n",
    "        \"client_count\": [\"mean\"],\n",
    "        \"operation\": [\"count\"],\n",
    "        \"amount\": [\"mean\", \"min\", \"max\", \"std\"],\n",
    "        \"type_transaction\": [count_withdrawal, count_credit]\n",
    "    })\n",
    "\n",
    "    df[\"num_times_under_zero\"] = num_times_under_zero\n",
    "\n",
    "    df.columns = ['%s%s' % (a, '_%s' % b if b else '') for a, b in df.columns]\n",
    "\n",
    "    # Account age at time of loan in days\n",
    "    df[\"account_age\"] = (df['loan_date'] - df['creation_date']).dt.days\n",
    "\n",
    "    # Number of days since last transaction\n",
    "    df[\"days_since_last_transaction\"] = (df[\"loan_date\"] - df[\"transaction_date_max\"]).dt.days\n",
    "\n",
    "    # Whether an account has reached a negative balance\n",
    "    # df[\"reached_negative_balance\"] = df[\"balance_min\"] < 0\n",
    "\n",
    "    # Drop non-numeric columns\n",
    "    loan_dfs[i] = df.select_dtypes([\"number\", \"bool\"])\n",
    "\n",
    "    # loan_dfs[i].drop([\"balance_min\", \"balance_max\"], axis=1, inplace=True)\n",
    "\n",
    "    status = loan_dfs[i].pop(\"status\")\n",
    "    loan_dfs[i][\"status\"] = status\n",
    "\n",
    "loan_train_df, loan_test_df = loan_dfs\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "loan_train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Age distribution by loan request\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of loans\")\n",
    "\n",
    "sb.histplot(data=loan_train_df, x=\"age\", hue=\"status\", bins=20).set(title=\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=loan_train_df, x=loan_train_df[\"loan_amount\"], hue=\"status\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "sb.scatterplot(x=loan_train_df[\"average salary\"], y=loan_train_df[\"loan_amount\"], marker=\"x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = loan_train_df.drop(\"loan_id\", axis=1).corr(method='spearman')\n",
    "\n",
    "threshold = 0.05\n",
    "\n",
    "correlation_status = corr_matrix.loc[['status'], :]\n",
    "selected_cols = set(correlation_status.loc[:, (abs(correlation_status) > threshold).any()].columns.to_list())\n",
    "dropped_cols = set.difference(set(correlation_status.columns.to_list()), selected_cols)\n",
    "\n",
    "loan_train_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "loan_test_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "\n",
    "corr_matrix = loan_train_df.drop(\"loan_id\", axis=1).corr(method='spearman')\n",
    "\n",
    "mask = np.zeros(corr_matrix.shape, dtype=bool)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "mask[np.triu_indices(len(mask))] = True\n",
    "\n",
    "plt.title('Correlation Heatmap of client Dataset')\n",
    "\n",
    "sb.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black', mask=mask)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export preprocessed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train_df.to_pickle(\"../out/train.pkl\")\n",
    "loan_test_df.to_pickle(\"../out/test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
